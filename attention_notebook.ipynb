{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "06fb04b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4, 1])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "BATCH_SIZE = 1\n",
    "SEQ_LEN = 4\n",
    "EMBEDDING_SIZE = 1\n",
    "\n",
    "def build_input_data(batch_size, seq_len, embedding_size):\n",
    "    \"\"\"\n",
    "    Build a random input data tensor.\n",
    "    \"\"\"\n",
    "    return torch.randn(batch_size, seq_len, embedding_size)\n",
    "# batch size 4, each sequence of length 3, with embedding size 2\n",
    "data = build_input_data(BATCH_SIZE, SEQ_LEN, EMBEDDING_SIZE)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f259f3a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q shape: torch.Size([1, 4, 4])\n",
      "K shape: torch.Size([1, 4, 4])\n",
      "V shape: torch.Size([1, 4, 4])\n",
      "Scores shape: torch.Size([1, 4, 4])\n",
      "Scores: tensor([[[ 5.6724e-04,  4.8002e-02,  4.9069e-03,  2.1055e-02],\n",
      "         [ 1.3777e-02,  1.1659e+00,  1.1918e-01,  5.1139e-01],\n",
      "         [ 1.1793e-02,  9.9798e-01,  1.0202e-01,  4.3775e-01],\n",
      "         [-6.8609e-03, -5.8059e-01, -5.9350e-02, -2.5467e-01]]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "Alpha shape: torch.Size([1, 4, 4])\n",
      "Alpha: tensor([[[0.2489, 0.1393, 0.2403, 0.2037],\n",
      "         [0.2522, 0.4261, 0.2694, 0.3326],\n",
      "         [0.2517, 0.3603, 0.2648, 0.3090],\n",
      "         [0.2471, 0.0743, 0.2254, 0.1546]]], grad_fn=<SoftmaxBackward0>)\n",
      "Attention Output shape: torch.Size([1, 4, 4])\n",
      "Attention Output: tensor([[[-1.4934e-04,  1.6694e-03, -4.9704e-03,  5.4330e-03],\n",
      "         [-1.3125e-02,  4.4282e-01, -4.8328e-01,  7.6943e-01],\n",
      "         [-3.5166e-03,  1.0051e-01, -1.2754e-01,  1.9191e-01],\n",
      "         [ 3.6653e-03, -2.2016e-02,  1.1525e-01, -1.0197e-01]]],\n",
      "       grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "WQ = nn.Linear(EMBEDDING_SIZE, SEQ_LEN, bias=False)\n",
    "WK = nn.Linear(EMBEDDING_SIZE, SEQ_LEN, bias=False)\n",
    "WV = nn.Linear(EMBEDDING_SIZE, SEQ_LEN, bias=False)\n",
    "\n",
    "Q = WQ(data)\n",
    "K = WK(data)\n",
    "V = WV(data)    \n",
    "\n",
    "print(\"Q shape:\", Q.shape)\n",
    "print(\"K shape:\", K.shape)  \n",
    "print(\"V shape:\", V.shape)\n",
    "\n",
    "scores = Q*K.transpose(1,2)\n",
    "print(\"Scores shape:\", scores.shape)\n",
    "print(\"Scores:\", scores)\n",
    "alpha = torch.softmax(scores, dim=1)\n",
    "print(\"Alpha shape:\", alpha.shape)\n",
    "print(\"Alpha:\", alpha)\n",
    "\n",
    "attention_output = alpha * V\n",
    "print(\"Attention Output shape:\", attention_output.shape)\n",
    "print(\"Attention Output:\", attention_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fd7f5ab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words shape: (4, 3)\n",
      "W_Q shape: (3, 3)\n",
      "W_K shape: (3, 3)\n",
      "W_V shape: (3, 3)\n",
      "Q shape: (4, 3)\n",
      "K shape: (4, 3)\n",
      "V shape: (4, 3)\n",
      "Scores shape: (4, 4)\n",
      "Scores: [[ 8  2 10  2]\n",
      " [ 4  0  4  0]\n",
      " [12  2 14  2]\n",
      " [10  4 14  3]]\n",
      "Weights shape: (4, 4)\n",
      "Weights: [[2.36089863e-01 7.38987555e-03 7.49130386e-01 7.38987555e-03]\n",
      " [4.54826323e-01 4.51736775e-02 4.54826323e-01 4.51736775e-02]\n",
      " [2.39275049e-01 7.43870015e-04 7.59237211e-01 7.43870015e-04]\n",
      " [8.99501754e-02 2.81554063e-03 9.05653685e-01 1.58059922e-03]]\n",
      "[[0.98522025 1.74174051 0.75652026]\n",
      " [0.90965265 1.40965265 0.5       ]\n",
      " [0.99851226 1.75849334 0.75998108]\n",
      " [0.99560386 1.90407309 0.90846923]]\n"
     ]
    }
   ],
   "source": [
    "from numpy import array\n",
    "from numpy import random\n",
    "from numpy import dot\n",
    "from scipy.special import softmax\n",
    "\n",
    "# encoder representations of four different words\n",
    "word_1 = array([1, 0, 0])\n",
    "word_2 = array([0, 1, 0])\n",
    "word_3 = array([1, 1, 0])\n",
    "word_4 = array([0, 0, 1])\n",
    "\n",
    "# stacking the word embeddings into a single array\n",
    "words = array([word_1, word_2, word_3, word_4])\n",
    "print(\"Words shape:\", words.shape)\n",
    "\n",
    "# generating the weight matrices\n",
    "random.seed(42)\n",
    "W_Q = random.randint(3, size=(3, 3))\n",
    "W_K = random.randint(3, size=(3, 3))\n",
    "W_V = random.randint(3, size=(3, 3))\n",
    "print(\"W_Q shape:\", W_Q.shape)\n",
    "print(\"W_K shape:\", W_K.shape)  \n",
    "print(\"W_V shape:\", W_V.shape)\n",
    "\n",
    "# generating the queries, keys and values\n",
    "Q = words @ W_Q\n",
    "K = words @ W_K\n",
    "V = words @ W_V\n",
    "print(\"Q shape:\", Q.shape)\n",
    "print(\"K shape:\", K.shape)  \n",
    "print(\"V shape:\", V.shape)\n",
    "\n",
    "# scoring the query vectors against all key vectors\n",
    "scores = Q @ K.transpose()\n",
    "print(\"Scores shape:\", scores.shape)\n",
    "print(\"Scores:\", scores)\n",
    "# computing the weights by a softmax operation\n",
    "weights = softmax(scores / K.shape[1] ** 0.5, axis=1)\n",
    "print(\"Weights shape:\", weights.shape)\n",
    "print(\"Weights:\", weights)\n",
    "\n",
    "# computing the attention by a weighted sum of the value vectors\n",
    "attention = weights @ V\n",
    "\n",
    "print(attention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68327445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Life': 0, 'dessert': 1, 'eat': 2, 'first': 3, 'is': 4, 'short': 5}\n"
     ]
    }
   ],
   "source": [
    "sentence = 'Life is short, eat dessert first'\n",
    "\n",
    "dc = {s:i for i,s in enumerate(sorted(sentence.replace(',', '').split()))}\n",
    "print(dc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ee4c94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 4, 5, 2, 1, 3])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "sentence_int = torch.tensor([dc[s] for s in sentence.replace(',', '').split()])\n",
    "# Six words in the sentence, each represented by an integer\n",
    "print(sentence_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f88571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.3374, -0.1778, -0.3035, -0.5880,  0.3486,  0.6603, -0.2196, -0.3792,\n",
      "          0.7671, -1.1925,  0.6984, -1.4097,  0.1794,  1.8951,  0.4954,  0.2692],\n",
      "        [ 0.5146,  0.9938, -0.2587, -1.0826, -0.0444,  1.6236, -2.3229,  1.0878,\n",
      "          0.6716,  0.6933, -0.9487, -0.0765, -0.1526,  0.1167,  0.4403, -1.4465],\n",
      "        [ 0.2553, -0.5496,  1.0042,  0.8272, -0.3948,  0.4892, -0.2168, -1.7472,\n",
      "         -1.6025, -1.0764,  0.9031, -0.7218, -0.5951, -0.7112,  0.6230, -1.3729],\n",
      "        [-1.3250,  0.1784, -2.1338,  1.0524, -0.3885, -0.9343, -0.4991, -1.0867,\n",
      "          0.8805,  1.5542,  0.6266, -0.1755,  0.0983, -0.0935,  0.2662, -0.5850],\n",
      "        [-0.0770, -1.0205, -0.1690,  0.9178,  1.5810,  1.3010,  1.2753, -0.2010,\n",
      "          0.4965, -1.5723,  0.9666, -1.1481, -1.1589,  0.3255, -0.6315, -2.8400],\n",
      "        [ 0.8768,  1.6221, -1.4779,  1.1331, -1.2203,  1.3139,  1.0533,  0.1388,\n",
      "          2.2473, -0.8036, -0.2808,  0.7697, -0.6596, -0.7979,  0.1838,  0.2293]])\n",
      "torch.Size([6, 16])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "embed = torch.nn.Embedding(6, 16)\n",
    "embedded_sentence = embed(sentence_int).detach()\n",
    "\n",
    "print(embedded_sentence)\n",
    "print(embedded_sentence.shape)\n",
    "\n",
    "#Single sentence = 1 batch, 6 words, each word represented by a 16-dimensional vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ff7b4896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 24 24 28\n",
      "Q shape: torch.Size([6, 24])\n",
      "K shape: torch.Size([6, 24])\n",
      "V shape: torch.Size([6, 28])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "d = embedded_sentence.shape[1]\n",
    "\n",
    "d_q, d_k, d_v = 24, 24, 28\n",
    "\n",
    "print(d, d_q, d_k, d_v)\n",
    "\n",
    "W_query = torch.nn.Parameter(torch.rand(d_q, d))\n",
    "W_key = torch.nn.Parameter(torch.rand(d_k, d))\n",
    "W_value = torch.nn.Parameter(torch.rand(d_v, d))\n",
    "\n",
    "Q = (W_query @ embedded_sentence.T).T\n",
    "K = (W_key @ embedded_sentence.T).T\n",
    "V = (W_value @ embedded_sentence.T).T\n",
    "\n",
    "print(\"Q shape:\", Q.shape)\n",
    "print(\"K shape:\", K.shape)\n",
    "print(\"V shape:\", V.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b7c1d26a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "o shape: torch.Size([6, 6])\n",
      "o: tensor([[   2.4085,   -4.4031,  -40.0720,  -10.5427,  -24.6705,   44.0660],\n",
      "        [ -17.7738,    2.4781,   30.8294,    5.1670,    4.0020,  -22.7538],\n",
      "        [ -42.4927,  -11.8778,  132.2293,   39.5114,   61.3134, -141.9247],\n",
      "        [ -26.9960,  -12.5723,   90.3728,   36.1849,   37.4335,  -93.6340],\n",
      "        [ -24.8323,   -8.0015,   53.0754,    6.9425,   18.4449,  -66.0415],\n",
      "        [  39.0232,   16.4217, -112.1686,  -38.8169,  -57.1165,  128.8991]],\n",
      "       grad_fn=<MmBackward0>)\n",
      "Weights shape: torch.Size([6, 6])\n",
      "Weights: tensor([[2.0274e-04, 5.0478e-05, 3.4758e-08, 1.4415e-05, 8.0612e-07, 9.9973e-01],\n",
      "        [4.8515e-05, 3.0283e-03, 9.8753e-01, 5.2430e-03, 4.1334e-03, 1.7555e-05],\n",
      "        [3.2426e-16, 1.6784e-13, 1.0000e+00, 6.0333e-09, 5.1678e-07, 4.9688e-25],\n",
      "        [3.9378e-11, 7.4801e-10, 9.9996e-01, 1.5712e-05, 2.0273e-05, 4.8728e-17],\n",
      "        [1.2390e-07, 3.8470e-06, 9.9906e-01, 8.1267e-05, 8.5035e-04, 2.7535e-11],\n",
      "        [1.0777e-08, 1.0688e-10, 4.2594e-22, 1.3551e-15, 3.2339e-17, 1.0000e+00]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Attention shape: torch.Size([6, 28])\n",
      "Attention: tensor([[ 1.8755,  0.9784,  2.2814,  1.1528,  2.1907,  2.6666,  0.8499,  2.3582,\n",
      "          3.7353,  1.6071,  5.2255,  1.0654,  3.2257,  2.6495,  2.1405,  1.1015,\n",
      "          3.0383,  1.9574,  0.8971,  3.4690,  4.5852,  0.8633, -0.9389,  2.4056,\n",
      "          1.6515,  2.5953,  0.9048,  0.4403],\n",
      "        [-2.1321, -1.5724, -4.1006, -2.8867, -0.2457, -1.9407, -1.4758, -1.3471,\n",
      "         -1.9556, -2.9637, -3.9928, -2.1052, -2.1058, -0.0861, -1.2516, -0.8152,\n",
      "         -3.8073, -2.1848, -1.3756, -2.0466, -3.4833, -1.8697, -2.7215, -1.0424,\n",
      "         -2.7925, -0.6172, -2.3108, -1.4198],\n",
      "        [-2.1447, -1.5942, -4.1397, -2.9052, -0.2354, -1.9630, -1.4996, -1.3542,\n",
      "         -1.9672, -2.9772, -4.0340, -2.1068, -2.1127, -0.0817, -1.2597, -0.8012,\n",
      "         -3.8447, -2.2039, -1.3893, -2.0653, -3.5071, -1.8681, -2.7397, -1.0557,\n",
      "         -2.8248, -0.6203, -2.3346, -1.4420],\n",
      "        [-2.1447, -1.5941, -4.1396, -2.9052, -0.2354, -1.9629, -1.4996, -1.3542,\n",
      "         -1.9672, -2.9772, -4.0339, -2.1068, -2.1127, -0.0817, -1.2597, -0.8013,\n",
      "         -3.8446, -2.2038, -1.3892, -2.0653, -3.5071, -1.8681, -2.7397, -1.0557,\n",
      "         -2.8247, -0.6203, -2.3346, -1.4420],\n",
      "        [-2.1435, -1.5926, -4.1384, -2.9048, -0.2361, -1.9604, -1.4976, -1.3526,\n",
      "         -1.9656, -2.9769, -4.0317, -2.1072, -2.1107, -0.0823, -1.2591, -0.8012,\n",
      "         -3.8418, -2.2020, -1.3865, -2.0651, -3.5056, -1.8690, -2.7392, -1.0542,\n",
      "         -2.8224, -0.6199, -2.3330, -1.4405],\n",
      "        [ 1.8758,  0.9786,  2.2815,  1.1526,  2.1911,  2.6673,  0.8498,  2.3586,\n",
      "          3.7360,  1.6072,  5.2271,  1.0653,  3.2264,  2.6500,  2.1412,  1.1019,\n",
      "          3.0390,  1.9577,  0.8968,  3.4700,  4.5863,  0.8639, -0.9392,  2.4060,\n",
      "          1.6518,  2.5963,  0.9050,  0.4403]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "o = Q @ K.T \n",
    "print(\"o shape:\", o.shape)\n",
    "print(\"o:\", o)\n",
    "\n",
    "wts = torch.nn.functional.softmax(o/d_k**0.5, dim=1)\n",
    "print(\"Weights shape:\", wts.shape)\n",
    "print(\"Weights:\", wts)\n",
    "\n",
    "attention = wts @ V\n",
    "print(\"Attention shape:\", attention.shape)\n",
    "print(\"Attention:\", attention)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
